{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dab0c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header                         Details\n",
      "    h1 Wikipedia The Free Encyclopedia\n",
      "    h2             1 000 000+ articles\n",
      "    h2               100 000+ articles\n",
      "    h2                10 000+ articles\n",
      "    h2                 1 000+ articles\n",
      "    h2                   100+ articles\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "url1='https://www.wikipedia.org/'\n",
    "\n",
    "## 1 Write a python program to display all the header tags from wikipedia.org and make data frame.\n",
    "\n",
    "def wiki_header(url):\n",
    "    reqs = requests.get(url)\n",
    "    if reqs.status_code==200:\n",
    "        soup = bs(reqs.text, 'html.parser')\n",
    "        header=[]\n",
    "        header_str=[]\n",
    "        for heading in soup.find_all([\"h1\", \"h2\", \"h3\"]): \n",
    "            header.append(heading.name)\n",
    "            t1=heading.text\n",
    "            t1=t1.replace(\"\\n\", \"\\t\") #Make multiple header into single line\n",
    "            t1=\" \".join(t1.split())   #Remove the space between words and then join the string\n",
    "            header_str.append(t1)\n",
    "        \n",
    "        wiki_df = pd.DataFrame({'Header':header,'Details':header_str})\n",
    "        wiki_df =wiki_df.to_string(index=False) # remove the index column from the data frame\n",
    "    \n",
    "        print(wiki_df)\n",
    "    else:\n",
    "        print('Web Scrapping not allowed for this site.')\n",
    "        \n",
    "    \n",
    "wiki_header(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da57830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              President Name         Presidents Term\n",
      "        Shri Ram Nath Kovind 14th President of India\n",
      "       Shri Pranab Mukherjee 13th President of India\n",
      "Smt Pratibha Devisingh Patil 12th President of India\n",
      "      DR. A.P.J. Abdul Kalam 11th President of India\n",
      "        Shri K. R. Narayanan 10th President of India\n",
      "     Dr Shankar Dayal Sharma 9th  President of India\n",
      "         Shri R Venkataraman  8th President of India\n",
      "            Giani Zail Singh  7th President of India\n",
      "   Shri Neelam Sanjiva Reddy  6th President of India\n",
      "    Dr. Fakhruddin Ali Ahmed  5th President of India\n",
      "Shri Varahagiri Venkata Giri  4th President of India\n",
      "            Dr. Zakir Husain  3rd President of India\n",
      "Dr. Sarvepalli Radhakrishnan  2nd President of India\n",
      "         Dr. Rajendra Prasad  1st President of India\n"
     ]
    }
   ],
   "source": [
    "## Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice) \n",
    "## from https://presidentofindia.nic.in/former-presidents.htm and make data frame.\n",
    "\n",
    "url2 ='https://presidentofindia.nic.in/former-presidents'\n",
    "def ind_presi_list(url_name):\n",
    "    reqs = requests.get(url_name)\n",
    "    if reqs.status_code==200:\n",
    "        soup = bs(reqs.content)\n",
    "        pre_name=[]\n",
    "        pre_term=[]\n",
    "        for presi_names in soup.find_all('div',class_=\"desc-sec\"):\n",
    "            name=presi_names.find(\"h3\")\n",
    "            term=presi_names.find(\"h5\")\n",
    "            pre_name.append(name.text)\n",
    "            pre_term.append(term.text)\n",
    "        if len(pre_name)==len(pre_term):\n",
    "            pre_df=pd.DataFrame({'President Name':pre_name,'Presidents Term':pre_term})\n",
    "            pre_df=pre_df.to_string(index=False)\n",
    "        print(pre_df)\n",
    "    else:\n",
    "         print('Web Scrapping not allowed for this site.')\n",
    "        \n",
    "    \n",
    "    \n",
    "ind_presi_list(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f64b3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============TOP 10 ODI TEAM - MEN===========================\n",
      "\n",
      "Rank        Team Name Total Matches Total Points Ratings\n",
      "   1       India(IND)            49        5,839     119\n",
      "   2   Australia(AUS)            36        4,015     112\n",
      "   3    Pakistan(PAK)            32        3,525     110\n",
      "   4 South Africa(SA)            29        3,166     109\n",
      "   5  New Zealand(NZ)            38        4,007     105\n",
      "   6     England(ENG)            34        3,377      99\n",
      "   7    Sri Lanka(SL)            43        3,943      92\n",
      "   8  Bangladesh(BAN)            40        3,574      89\n",
      "   9 Afghanistan(AFG)            26        2,170      83\n",
      "  10  West Indies(WI)            38        2,582      68\n",
      "\n",
      "\n",
      "============TOP 10 ODI TEAM - WOMEN=========================\n",
      "\n",
      "Rank        Team Name Total Matches Total Points Ratings\n",
      "   1   Australia(AUS)            19        3,084     162\n",
      "   2     England(ENG)            23        2,991     130\n",
      "   3 South Africa(SA)            21        2,446     116\n",
      "   4       India(IND)            18        1,745      97\n",
      "   5  New Zealand(NZ)            21        2,014      96\n",
      "   6  West Indies(WI)            18        1,610      89\n",
      "   7    Sri Lanka(SL)             9          714      79\n",
      "   8  Bangladesh(BAN)            11          816      74\n",
      "   9    Thailand(THA)            11          753      68\n",
      "  10    Pakistan(PAK)            21        1,435      68\n"
     ]
    }
   ],
   "source": [
    "# Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame-\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "# b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "def top_10_odi(url_name):\n",
    "    reqs = requests.get(url_name)\n",
    "    if reqs.status_code==200:\n",
    "        soup = bs(reqs.content,'html.parser')\n",
    "        \n",
    "        rank=[]\n",
    "        team_name=[]\n",
    "        total_matches=[]\n",
    "        total_pts=[]\n",
    "        ratings=[]\n",
    "        \n",
    "        # Team Details from Banner\n",
    "        first_team           = soup.find('div',attrs={'class':'rankings-block__container full rankings-table'})\n",
    "        \n",
    "        ban_team_rank        = first_team.find('td',class_ ='rankings-block__banner--pos').text\n",
    "        rank.append(ban_team_rank)\n",
    "        \n",
    "        ban_team_con         = first_team.find('span',class_='u-hide-phablet').text\n",
    "        ban_team_con_abr     = first_team.find('span',class_='u-show-phablet').text\n",
    "        team_name.append(ban_team_con+'('+ban_team_con_abr+')')\n",
    "        \n",
    "        ban_team_tot_matches = first_team.find('td',class_='rankings-block__banner--matches').text\n",
    "        total_matches.append(ban_team_tot_matches)\n",
    "        \n",
    "        ban_team_tot_pts     = first_team.find('td',class_='rankings-block__banner--points').text\n",
    "        total_pts.append(ban_team_tot_pts )\n",
    "        \n",
    "        ban_team_ratings     = first_team.find('td',class_='rankings-block__banner--rating u-text-right').text\n",
    "        ban_team_ratings     = ban_team_ratings.replace('\\n','').replace(\" \",\"\")\n",
    "\n",
    "        ratings.append(ban_team_ratings)\n",
    "        \n",
    "         # Other Team Details \n",
    "            \n",
    "        rest_teams=soup.find_all('tr',attrs={'class':'table-body'})\n",
    "        \n",
    "        for x in rest_teams:\n",
    "            team_rank        = x.find('td',class_='table-body__cell table-body__cell--position u-text-right').text\n",
    "            rank.append(team_rank)\n",
    "\n",
    "            team_con         = x.find('span',class_='u-hide-phablet').text \n",
    "            team_con_abr     = x.find('span',class_='u-show-phablet').text\n",
    "            team_name.append(team_con+'('+team_con_abr+')')\n",
    "\n",
    "            # looping since their are two tags\n",
    "            l_cnt=0\n",
    "            for y in x.find_all('td',class_='table-body__cell u-center-text'):\n",
    "                l_cnt=l_cnt+1\n",
    "                if l_cnt==1:\n",
    "                    total_matches.append(y.text)\n",
    "                else:\n",
    "                    total_pts.append(y.text)\n",
    "\n",
    "\n",
    "            team_ratings     =x.find('td',class_='table-body__cell u-text-right rating').text\n",
    "            team_ratings     = team_ratings.replace('\\n','').replace(\" \",\"\")\n",
    "            ratings.append(team_ratings)\n",
    "            \n",
    "        ## Since we want top 10 ranks only, hence removing last elements from list\n",
    "        rank = rank[:10]\n",
    "        team_name = team_name[:10]\n",
    "        total_matches = total_matches[:10]\n",
    "        total_pts = total_pts[:10]\n",
    "        ratings =ratings[:10]\n",
    "        \n",
    "        top_10_men_odi_df = pd.DataFrame({'Rank':rank,\n",
    "                                          'Team Name':team_name,\n",
    "                                          'Total Matches':total_matches,\n",
    "                                          'Total Points':total_pts,\n",
    "                                          'Ratings':ratings\n",
    "                                         })\n",
    "        top_10_men_odi_df=top_10_men_odi_df.to_string(index=False)\n",
    "        print(top_10_men_odi_df)\n",
    "    else:\n",
    "        print('Web Scrapping not allowed for this site.')\n",
    "        \n",
    "url3 ='https://www.icc-cricket.com/rankings/mens/team-rankings/odi' \n",
    "print('')\n",
    "print('')\n",
    "print('============TOP 10 ODI TEAM - MEN===========================')\n",
    "print('')\n",
    "top_10_odi(url3)\n",
    "print('')\n",
    "print('')\n",
    "print('============TOP 10 ODI TEAM - WOMEN=========================')\n",
    "print('')\n",
    "url4='https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "top_10_odi(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21eb8c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ TOP 10 ODI BATTER - MEN ===========================\n",
      "\n",
      "Rank          Batsman Name Batsman From Batsman Ratings\n",
      "   1            Babar Azam          PAK             829\n",
      "   2          Shubman Gill          IND             823\n",
      "   3       Quinton de Kock           SA             769\n",
      "   4      Heinrich Klaasen           SA             756\n",
      "   5          David Warner          AUS             747\n",
      "   6           Virat Kohli          IND             747\n",
      "   7          Harry Tector          IRE             729\n",
      "   8          Rohit Sharma          IND             725\n",
      "   9 Rassie van der Dussen           SA             716\n",
      "  10           Imam-ul-Haq          PAK             704\n",
      "\n",
      "\n",
      "============ TOP 10 ODI BATTER - WOMEN ==========================\n",
      "\n",
      "Rank         Batsman Name Batsman From Batsman Ratings\n",
      "   1 Natalie Sciver-Brunt          ENG             807\n",
      "   2          Beth Mooney          AUS             750\n",
      "   3  Chamari Athapaththu           SL             736\n",
      "   4      Laura Wolvaardt           SA             727\n",
      "   5      Smriti Mandhana          IND             708\n",
      "   6         Alyssa Healy          AUS             698\n",
      "   7         Ellyse Perry          AUS             697\n",
      "   8     Harmanpreet Kaur          IND             694\n",
      "   9          Meg Lanning          AUS             662\n",
      "  10       Marizanne Kapp           SA             642\n"
     ]
    }
   ],
   "source": [
    "def top_10_odi_batsmen(url_name):\n",
    "    reqs = requests.get(url_name)\n",
    "    if reqs.status_code==200:\n",
    "        soup = bs(reqs.content,'html.parser')\n",
    "        data= soup.find('table',attrs={'class':'table rankings-table'})\n",
    "        \n",
    "        bt_rank=[]\n",
    "        bt_name=[]\n",
    "        bt_con=[]\n",
    "        bt_rat=[]\n",
    "        \n",
    "        # Batsmens Details from Banner\n",
    "        ban_bat_rank=data.find('span',class_='rankings-block__pos-number').text.replace('\\n','').replace(\" \",\"\")\n",
    "        bt_rank.append(ban_bat_rank)\n",
    "        \n",
    "        ban_bat_name= data.find('div',class_='rankings-block__banner--name-large').text\n",
    "        bt_name.append(ban_bat_name)\n",
    "        \n",
    "        ban_bat_con=data.find('div',class_='rankings-block__banner--nationality').text.replace('\\n','').replace(\" \",\"\")\n",
    "        bt_con.append(ban_bat_con)\n",
    "        \n",
    "        ban_bat_rat=data.find('div',class_='rankings-block__banner--rating').text\n",
    "        bt_rat.append(ban_bat_rat)\n",
    "        \n",
    "        # Other Batsmen  Details \n",
    "        other_batsmen =soup.find_all('tr',attrs={'class':'table-body'})\n",
    "        for y in other_batsmen:\n",
    "            bat_rank=y.find('span',class_='rankings-table__pos-number').text.replace('\\n','').replace(\" \",\"\")\n",
    "            bt_rank.append(bat_rank)\n",
    "            \n",
    "            bat_name=y.find('td',class_=\"table-body__cell rankings-table__name name\").text.replace('\\n','')\n",
    "            bt_name.append(bat_name)\n",
    "            \n",
    "            bat_con=y.find('span',class_=\"table-body__logo-text\").text\n",
    "            bt_con.append(bat_con)\n",
    "            \n",
    "            bat_rat=y.find('td',class_=\"table-body__cell rating\").text\n",
    "            bt_rat.append(bat_rat)\n",
    "        \n",
    "        # Keep First 10 details from the list\n",
    "        bt_rank=bt_rank[:10]\n",
    "        bt_name=bt_name[:10]\n",
    "        bt_con=bt_con[:10]\n",
    "        bt_rat=bt_rat[:10]\n",
    "        # print(bt_rank)\n",
    "        # Assigning rank where equal sign is present\n",
    "        for i,e in enumerate(bt_rank[:-1], 1):\n",
    "            if bt_rank[i] == '=':\n",
    "                bt_rank[i] = int(bt_rank[(i-1)])+1   #Incrementing the previous list value with 1 and replace the = \n",
    "        # print(bt_rank)\n",
    "        \n",
    "        if len(bt_rank)==len(bt_name)==len(bt_con)==len(bt_rat):\n",
    "            top_10_batsmen_df=pd.DataFrame({'Rank':bt_rank,\n",
    "                                            'Batsman Name':bt_name,\n",
    "                                            'Batsman From':bt_con,\n",
    "                                            'Batsman Ratings':bt_rat})\n",
    "            top_10_batsmen_df=top_10_batsmen_df.to_string(index=False)\n",
    "            print(top_10_batsmen_df)\n",
    "        else:\n",
    "            print('Data Frame Cannot be created.......length mismatch')\n",
    "    else:\n",
    "        print('Web Scrapping not allowed for this site.')\n",
    "        \n",
    "url5 ='https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "print('')\n",
    "print('')\n",
    "print('============ TOP 10 ODI BATTER - MEN ===========================')\n",
    "print('')\n",
    "top_10_odi_batsmen(url5)\n",
    "print('')\n",
    "print('')\n",
    "print('============ TOP 10 ODI BATTER - WOMEN ==========================')\n",
    "print('')\n",
    "url6='https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "top_10_odi_batsmen(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3ecfd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ TOP 10 ODI BOWLING - MEN ===========================\n",
      "\n",
      "Rank   Bowlers Name Bowler From Bowler Ratings\n",
      "   1 Josh Hazlewood         AUS            670\n",
      "   2 Mohammed Siraj         IND            668\n",
      "   3 Keshav Maharaj          SA            656\n",
      "   4    Rashid Khan         AFG            654\n",
      "   5    Trent Boult          NZ            653\n",
      "   6  Mohammad Nabi         AFG            641\n",
      "   7     Adam Zampa         AUS            635\n",
      "   8     Matt Henry          NZ            634\n",
      "   9  Kuldeep Yadav         IND            632\n",
      "  10 Shaheen Afridi         PAK            625\n",
      "\n",
      "\n",
      "============ TOP 10 ODI BOWLING - WOMEN ==========================\n",
      "\n",
      "Rank      Bowlers Name Bowler From Bowler Ratings\n",
      "   1 Sophie Ecclestone         ENG            746\n",
      "   2    Shabnim Ismail          SA            680\n",
      "   3     Jess Jonassen         AUS            662\n",
      "   4      Megan Schutt         AUS            658\n",
      "   5  Ashleigh Gardner         AUS            652\n",
      "   6    Ayabonga Khaka          SA            640\n",
      "   7        Kate Cross         ENG            628\n",
      "   8   Hayley Matthews          WI            625\n",
      "   9     Deepti Sharma         IND            607\n",
      "  10    Marizanne Kapp          SA            600\n",
      "\n",
      "\n",
      "============ TOP 10 ODI ALLROUNDER - WOMEN ==========================\n",
      "\n",
      "Rank     All Rounder Name All Rounder From All Rounder Ratings\n",
      "   1       Marizanne Kapp               SA                 385\n",
      "   2     Ashleigh Gardner              AUS                 377\n",
      "   3 Natalie Sciver-Brunt              ENG                 360\n",
      "   4      Hayley Matthews               WI                 358\n",
      "   5          Amelia Kerr               NZ                 346\n",
      "   6        Deepti Sharma              IND                 312\n",
      "   7         Ellyse Perry              AUS                 282\n",
      "   8        Jess Jonassen              AUS                 227\n",
      "   9        Sophie Devine               NZ                 227\n",
      "  10             Nida Dar              PAK                 224\n"
     ]
    }
   ],
   "source": [
    "def top_10_odi_bowler(url_name):\n",
    "    reqs = requests.get(url_name)\n",
    "    if reqs.status_code==200:\n",
    "        soup = bs(reqs.content,'html.parser')\n",
    "        data= soup.find('table',attrs={'class':'table rankings-table'})\n",
    "        \n",
    "        bow_rank=[]\n",
    "        bow_name=[]\n",
    "        bow_con=[]\n",
    "        bow_rat=[]\n",
    "        \n",
    "        # Batsmens Details from Banner\n",
    "        ban_bow_rank=data.find('span',class_='rankings-block__pos-number').text.replace('\\n','').replace(\" \",\"\")\n",
    "        bow_rank.append(ban_bow_rank)\n",
    "        \n",
    "        ban_bow_name= data.find('div',class_='rankings-block__banner--name-large').text\n",
    "        bow_name.append(ban_bow_name)\n",
    "        \n",
    "        ban_bow_con=data.find('div',class_='rankings-block__banner--nationality').text.replace('\\n','').replace(\" \",\"\")\n",
    "        bow_con.append(ban_bow_con)\n",
    "        \n",
    "        ban_bow_rat=data.find('div',class_='rankings-block__banner--rating').text\n",
    "        bow_rat.append(ban_bow_rat)\n",
    "        \n",
    "        \n",
    "        # Other Bowler  Details\n",
    "        other_bowlers =soup.find_all('tr',attrs={'class':'table-body'})\n",
    "        for z in other_bowlers:\n",
    "            bw_rank=z.find('span',class_='rankings-table__pos-number').text.replace('\\n','').replace(\" \",\"\")\n",
    "            bow_rank.append(bw_rank)\n",
    "            \n",
    "            bw_name=z.find('td',class_=\"table-body__cell rankings-table__name name\").text.replace('\\n','')\n",
    "            bow_name.append(bw_name)\n",
    "            \n",
    "            bw_con=z.find('span',class_=\"table-body__logo-text\").text\n",
    "            bow_con.append(bw_con)\n",
    "            \n",
    "            bw_rat=z.find('td',class_=\"table-body__cell rating\").text\n",
    "            bow_rat.append(bw_rat)\n",
    "        \n",
    "        # Keep First 10 details from the list\n",
    "        bow_rank=bow_rank[:10]\n",
    "        bow_name=bow_name[:10]\n",
    "        bow_con=bow_con[:10]\n",
    "        bow_rat=bow_rat[:10]\n",
    "        \n",
    "        # Assigning rank where equal sign is present\n",
    "        for i,e in enumerate(bow_rank[:-1], 1):\n",
    "            if bow_rank[i] == '=':\n",
    "                bow_rank[i] = int(bow_rank[(i-1)])+1   #Incrementing the previous list value with 1 and replace the = \n",
    "        \n",
    "        if len(bow_rank)==len(bow_name)==len(bow_con)==len(bow_rat):\n",
    "            if url_name.count('all-rounder')==0:\n",
    "                top_10_bowlers_df=pd.DataFrame({'Rank':bow_rank,\n",
    "                                                'Bowlers Name':bow_name,\n",
    "                                                'Bowler From':bow_con,\n",
    "                                                'Bowler Ratings':bow_rat})\n",
    "                top_10_bowlers_df=top_10_bowlers_df.to_string(index=False)\n",
    "                print(top_10_bowlers_df)\n",
    "            else:\n",
    "                top_10_bowlers_df=pd.DataFrame({'Rank':bow_rank,\n",
    "                                                'All Rounder Name':bow_name,\n",
    "                                                'All Rounder From':bow_con,\n",
    "                                                'All Rounder Ratings':bow_rat})\n",
    "                top_10_bowlers_df=top_10_bowlers_df.to_string(index=False)\n",
    "                print(top_10_bowlers_df)\n",
    "                \n",
    "            \n",
    "    else:\n",
    "        print('Web Scrapping not allowed for this site.')\n",
    "        \n",
    "url7='https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "print('')\n",
    "print('')\n",
    "print('============ TOP 10 ODI BOWLING - MEN ===========================')\n",
    "print('')\n",
    "top_10_odi_bowler(url7)\n",
    "print('')\n",
    "print('')\n",
    "print('============ TOP 10 ODI BOWLING - WOMEN ==========================')\n",
    "print('')\n",
    "url8='https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling'    \n",
    "top_10_odi_bowler(url8)\n",
    "print('')\n",
    "print('')\n",
    "print('============ TOP 10 ODI ALLROUNDER - WOMEN ==========================')\n",
    "print('')\n",
    "url9='https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "top_10_odi_bowler(url9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6694a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Headline              Time                                          News Link\n",
      "0   Cramer: This market has put investors in a box...       4 Hours Ago  https://www.cnbc.com/2023/10/29/cramer-this-ma...\n",
      "1   Google Bard asks Bill Nye if AI can help avoid...       5 Hours Ago  https://www.cnbc.com/2023/10/29/how-bill-nye-e...\n",
      "2   What's a good price to get into a stock that h...       5 Hours Ago  https://www.cnbc.com/2023/10/29/what-is-a-good...\n",
      "3   McDonald's HR exec: The No. 1 skill you get wo...       6 Hours Ago  https://www.cnbc.com/2023/10/29/mcdonalds-hr-e...\n",
      "4   The top 10 best states for millennials—New Yor...       6 Hours Ago  https://www.cnbc.com/2023/10/29/best-states-mi...\n",
      "5   As the market enters correction territory, don...       6 Hours Ago  https://www.cnbc.com/2023/10/29/dont-blame-the...\n",
      "6   The No. 1 most ‘overlooked’ skill kids with hi...       6 Hours Ago  https://www.cnbc.com/2023/10/29/kids-with-high...\n",
      "7   This 51-year-old makes an average of $10,000 p...       7 Hours Ago  https://www.cnbc.com/2023/10/29/nora-curl-make...\n",
      "8   Mark Cuban shares the 9-word mantra he learned...       7 Hours Ago  https://www.cnbc.com/2023/10/29/mark-cuban-lea...\n",
      "9   Improving your credit score by 100 points coul...       7 Hours Ago  https://www.cnbc.com/2023/10/29/how-much-money...\n",
      "10  Here's how to take .5 selfies — the super wide...       7 Hours Ago  https://www.cnbc.com/2023/10/29/how-to-take-po...\n",
      "11  Some pharmacy staff from Walgreens, other chai...       8 Hours Ago  https://www.cnbc.com/2023/10/29/pharmacy-staff...\n",
      "12  Biden administration has forgiven $127 billion...       8 Hours Ago  https://www.cnbc.com/2023/10/29/biden-administ...\n",
      "13  Earnings calls reveal how an array of companie...       9 Hours Ago  https://www.cnbc.com/2023/10/29/earnings-calls...\n",
      "14  Here are 5 anti-obesity drug stocks to watch i...       9 Hours Ago  https://www.cnbc.com/2023/10/29/here-are-5-ant...\n",
      "15  Earnings playbook: Your guide to trading anoth...       9 Hours Ago  https://www.cnbc.com/2023/10/29/earnings-playb...\n",
      "16  Thousands break into UN warehouses in Gaza; Is...      12 Hours Ago  https://www.cnbc.com/2023/10/29/israel-hamas-w...\n",
      "17  Jamie Dimon's stock-moving trades show benefit...  October 28, 2023  https://www.cnbc.com/2023/10/28/jamie-dimon-tr...\n",
      "18  Mike Pence ends campaign for the White House a...  October 28, 2023  https://www.cnbc.com/2023/10/28/former-vice-pr...\n",
      "19  UAW in tentative deal to end labor strike with...  October 28, 2023  https://www.cnbc.com/2023/10/28/uaw-strike-ste...\n",
      "20  Suze Orman: ‘Big mistake if you park your mone...  October 28, 2023  https://www.cnbc.com/2023/10/28/suze-orman-big...\n",
      "21  Jobs and earnings are major themes next week a...  October 28, 2023  https://www.cnbc.com/2023/10/28/jobs-earnings-...\n",
      "22  Here's Americans' net worth at every age—for p...  October 28, 2023  https://www.cnbc.com/2023/10/28/americans-medi...\n",
      "23  Psychologist: Here's my No.1 brain hack for cr...  October 28, 2023  https://www.cnbc.com/2023/10/28/uchicago-psych...\n",
      "24  Routine S&P 500 correction or something more s...  October 28, 2023  https://www.cnbc.com/2023/10/28/analyzing-the-...\n",
      "25     Why it's so expensive to be single in the U.S.  October 28, 2023  https://www.cnbc.com/2023/10/28/why-its-so-exp...\n",
      "26  Use this Google feature to detect and delete y...  October 28, 2023  https://www.cnbc.com/2023/10/28/how-to-delete-...\n",
      "27  Reddit co-founder: Most successful people shar...  October 28, 2023  https://www.cnbc.com/2023/10/28/reddit-co-foun...\n",
      "28  'Earn Your Leisure' hosts: It may take $10 mil...  October 28, 2023  https://www.cnbc.com/2023/10/28/earn-your-leis...\n",
      "29  Coke and Pepsi stocks are struggling — but one...  October 28, 2023  https://www.cnbc.com/2023/10/28/coke-and-pepsi...\n"
     ]
    }
   ],
   "source": [
    "# 5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame-\n",
    "# i) Headline\n",
    "# ii) Time\n",
    "# iii) News Link\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "def news_details(url_name):\n",
    "    response = requests.get(url_name)\n",
    "    soup = bs(response.content,'lxml')\n",
    "\n",
    "    all_news = soup.find('ul',class_='LatestNews-list').find_all('li',class_='LatestNews-item')\n",
    "\n",
    "    headline = []\n",
    "    time = []\n",
    "    newslink =[]\n",
    "\n",
    "    for x in all_news:\n",
    "        ts = x.find('time',class_='LatestNews-timestamp').text\n",
    "        time.append(ts)\n",
    "        ti = x.find('div',class_='LatestNews-headlineWrapper').text\n",
    "        ti = ti.replace(ts, \"\") \n",
    "        headline.append(ti)\n",
    "        li = x.find('a',attrs={'href': re.compile(\"^https://\")}).get('href') \n",
    "        newslink.append(li)\n",
    "    \n",
    "    news_det_df = pd.DataFrame({'Headline':headline,'Time':time,'News Link':newslink})\n",
    "    print(news_det_df)\n",
    "\n",
    "url10=\"https://www.cnbc.com/world/?region=world\"\n",
    "news_details(url10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d40d196d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Title                                            Authors  Published Date                                          Paper URL\n",
      "0                                    Reward is enough  David Silver, Satinder Singh, Doina Precup, Ri...    October 2021  https://www.sciencedirect.com/science/article/...\n",
      "1   Explanation in artificial intelligence: Insigh...                                        Tim Miller    February 2019  https://www.sciencedirect.com/science/article/...\n",
      "2              Creativity and artificial intelligence                                 Margaret A. Boden      August 1998  https://www.sciencedirect.com/science/article/...\n",
      "3   Conflict-based search for optimal multi-agent ...  Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015  https://www.sciencedirect.com/science/article/...\n",
      "4   Knowledge graphs as tools for explainable mach...                    Ilaria Tiddi, Stefan Schlobach     January 2022  https://www.sciencedirect.com/science/article/...\n",
      "5   Law and logic: A review from an argumentation ...                    Henry Prakken, Giovanni Sartor     October 2015  https://www.sciencedirect.com/science/article/...\n",
      "6   Between MDPs and semi-MDPs: A framework for te...   Richard S. Sutton, Doina Precup, Satinder Singh      August 1999  https://www.sciencedirect.com/science/article/...\n",
      "7   Explaining individual predictions when feature...         Kjersti Aas, Martin Jullum, Anders Løland   September 2021  https://www.sciencedirect.com/science/article/...\n",
      "8       Multiple object tracking: A literature review               Wenhan Luo, Junliang Xing and 4 more      April 2021  https://www.sciencedirect.com/science/article/...\n",
      "9   A survey of inverse reinforcement learning: Ch...                     Saurabh Arora, Prashant Doshi      August 2021  https://www.sciencedirect.com/science/article/...\n",
      "10  Evaluating XAI: A comparison of rule-based and...  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021  https://www.sciencedirect.com/science/article/...\n",
      "11  Explainable AI tools for legal reasoning about...  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023  https://www.sciencedirect.com/science/article/...\n",
      "12            Hard choices in artificial intelligence  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021  https://www.sciencedirect.com/science/article/...\n",
      "13  Assessing the communication gap between AI mod...  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023  https://www.sciencedirect.com/science/article/...\n",
      "14  Explaining black-box classifiers using post-ho...  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021  https://www.sciencedirect.com/science/article/...\n",
      "15  The Hanabi challenge: A new frontier for AI re...          Nolan Bard, Jakob N. Foerster and 13 more      March 2020  https://www.sciencedirect.com/science/article/...\n",
      "16              Wrappers for feature subset selection                        Ron Kohavi, George H. John    December 1997  https://www.sciencedirect.com/science/article/...\n",
      "17  Artificial cognition for social human–robot in...      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017  https://www.sciencedirect.com/science/article/...\n",
      "18  A review of possible effects of cognitive bias...   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021  https://www.sciencedirect.com/science/article/...\n",
      "19  The multifaceted impact of Ada Lovelace in the...                            Luigia Carlucci Aiello        June 2016  https://www.sciencedirect.com/science/article/...\n",
      "20  Robot ethics: Mapping the issues for a mechani...            Patrick Lin, Keith Abney, George Bekey       April 2011  https://www.sciencedirect.com/science/article/...\n",
      "21          Reward (Mis)design for autonomous driving     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023  https://www.sciencedirect.com/science/article/...\n",
      "22  Planning and acting in partially observable st...  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998  https://www.sciencedirect.com/science/article/...\n",
      "23  What do we want from Explainable Artificial In...             Markus Langer, Daniel Oster and 6 more       July 2021  https://www.sciencedirect.com/science/article/...\n"
     ]
    }
   ],
   "source": [
    "# 6) Write a python program to scrape the details of most downloaded articles from AI in last 90 days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details and make data frame-\n",
    "# i) Paper Title\n",
    "# ii) Authors\n",
    "# iii) Published Date\n",
    "# iv) Paper URL\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "def most_dwn_articles(url_name):\n",
    "    res = requests.get(url_name)\n",
    "    soup = bs(res.content,'html.parser')\n",
    "\n",
    "    all_data = soup.find('ul',class_='sc-9zxyh7-0 cMKaMj').find_all('li',class_='sc-9zxyh7-1 sc-9zxyh7-2 kOEIEO hvoVxs')\n",
    "    \n",
    "    t_list =[]\n",
    "    a_list =[]\n",
    "    p_list =[]\n",
    "    u_list =[]\n",
    "\n",
    "    for x in all_data:\n",
    "        title = x.find('h2',class_='sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg').text\n",
    "        t_list.append(title)\n",
    "        authors = x.find('span',class_='sc-1w3fpd7-0 dnCnAO').text\n",
    "        a_list.append(authors)\n",
    "        pubdt   = x.find('span',class_='sc-1thf9ly-2 dvggWt').text\n",
    "        p_list.append(pubdt)\n",
    "        purl    = x.find('a').get('href')\n",
    "        u_list.append(purl)\n",
    "    \n",
    "    dwn_df = pd.DataFrame({'Title':t_list,'Authors':a_list,'Published Date':p_list,'Paper URL':u_list})    \n",
    "    print(dwn_df)\n",
    "\n",
    "url11=\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "most_dwn_articles(url11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80419f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Restaurant Name                                   Cusine                                           Location Ratings                                         Images URL\n",
      "0       Sigree Global Grill                    North Indian, Biryani                      Ventura Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "1            Mainland China                     Chinese, Asian, Thai                                 Hiranandani, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "2             Kake Da Hotel           Chinese, North Indian, Biryani                     Vikhroli West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "3                   Thambbi               South Indian, North Indian  Kailash Business Park,Vikhroli West, Central S...   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "4   Sbarro - New York Pizza      Pizza, Fast Food, American, Italian  Kailash Business Park,Vikhroli West, Central S...   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "5                   Malgudi                             South Indian        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "6               Urban Tadka                    North Indian, Mughlai        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "7             Kannu ki Chai                         Street Food, Tea                     Vikhroli West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "8             Charcoal Eats         Biryani, North Indian, Fast Food           Heera Panna Shopping Centre,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "9             Frozen Bottle                      Desserts, Beverages        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "10        Khandani Rajdhani       Gujarati, Rajasthani, North Indian        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "11         Grandmama's Cafe          Continental, Italian, Beverages        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "12          Mad Over Donuts                      Desserts, Beverages        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "13        House of Mandarin                 Asian, Chinese, Japanese                       Delphi Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "14          Mad Over Donuts                      Desserts, Beverages                    City Park Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "15         Ministry Of Eggs                 Continental, Health Food        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "16  Sbarro - New York Pizza      Pizza, Fast Food, American, Italian        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "17                 Cinnabon                                 Desserts        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "18                Taco Bell                                  Tex Mex        R City Mall,Ghatkopar West, Central Suburbs   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "19       Lord of the Drinks   Chinese, European, Asian, North Indian                                       Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n",
      "20             PizzaExpress                Italian, Pizza, Beverages                      Ventura Building,Powai, Powai   [4.3]  https://im1.dineout.co.in/images/uploads/resta...\n"
     ]
    }
   ],
   "source": [
    "# 7) Write a python program to scrape mentioned details from dineout.co.in and make data frame-\n",
    "# i) Restaurant name\n",
    "# ii) Cuisine\n",
    "# iii) Location\n",
    "# iv) Ratings\n",
    "# v) Image URL\n",
    "\n",
    "def dine_out(url_name):\n",
    "    req  = requests.get(url_name)\n",
    "    soup = bs(req.content,'lxml')\n",
    "    \n",
    "    name_list = []\n",
    "    cusine_list =[]\n",
    "    location_list =[]\n",
    "    ratings_list =[]\n",
    "    images_url_list =[]\n",
    "\n",
    "    all_rest_data = soup.find('div',class_='restnt-card-wrap-new')\n",
    "    \n",
    "    for det in all_rest_data:\n",
    "        name = det.find('a').text\n",
    "        name_list.append(name)\n",
    "        cus = det.find('span',class_='double-line-ellipsis').text.split('|') \n",
    "        cus[1]\n",
    "              ## cus[0] is ₹ 1,200 for 2 (approx) \n",
    "              ## cus[1] is Continental, North Indian cusine\n",
    "        cusine_list.append(cus[1])\n",
    "        loc = det.find('div',class_='restnt-loc ellipsis').text\n",
    "        location_list.append(loc)\n",
    "        images = det.find('img',class_='no-img').get('data-src')\n",
    "        images_url_list.append(images)\n",
    "        rat = det.find('div',class_='restnt-rating rating-4 hide') ## not able to derive the ratings correctly\n",
    "        ratings_list.append(rat)\n",
    "\n",
    "    dineout_df = pd.DataFrame({'Restaurant Name':name_list,'Cusine':cusine_list,'Location':location_list,'Ratings':ratings_list,'Images URL':images_url_list})\n",
    "    print(dineout_df)\n",
    "    \n",
    "url12='https://www.dineout.co.in/mumbai-restaurants/welcome-back'\n",
    "dine_out(url12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab116d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
